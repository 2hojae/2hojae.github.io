---
permalink: /
title: "Hi Ther@#@#@#e!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hiüëã I'm Hojae! I recently obtained M.S in Computer Science and Engineering from Korea University, where I was advised by [Prof. SangKeun Lee](http://dilab.korea.ac.kr/?page_id=658).  Previously, I obtained B.A. in English Linguistics and B.L.S. in Language & AI from Hankuk University of Foreign Studies.

My primary research lies in the area of Natural Language Processing, generally in aligning human virtues and behaviors with language models. My research topics are: **1) Complex Reasoning, 2) Efficient NLP**, and **3) Computational Linguistics**. Specifically, I am interested in *what* knowledge is nested in the parameters of pre-trained language models, *how* to utilize and improve their knowledge for complex reasoning, while preserving efficiency for training/inference complexities.



Publications
======
[Mentor-KD: Making Small Language Models Better Multi-step Reasoners](https://drive.google.com/file/d/1sVk8waYMglwtGbkJ_rNU1NxTiUzw_rkB/view?usp=sharing) \
**Hojae Lee***, Junho Kim*, SangKeun Lee \
**EMNLP 2024 (long)**; _to appear_

Improving Chain-of-Thought Distillation with Annotator Models \
**Hojae Lee** \
**KCC 2024**


News
======
 **I am _actively_ looking for PhD opportunities in North America or South Korea üßë‚Äçüéì**
- [09.2024] Excited to announce that our paper "Mentor-KD: Making Small Language Models Better Multi-step Reasoners" has been accepted to EMNLP 2024. See you in Miami! ‚õ±Ô∏è
- [06.2024] Successfully defended and officially a Master now! üéì